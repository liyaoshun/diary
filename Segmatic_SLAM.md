#   **第一期：语义 SLAM 技术探讨**
[LINK](https://mp.weixin.qq.com/s?__biz=MzI5MTM1MTQwMw==&mid=2247522823&idx=1&sn=8a3f4e3e331083c785974509a5fa3473&chksm=ec132403db64ad152542cb6869b6610c469d62edba65dffd932c0fb0f510573c7c6119bef4cb&scene=0&xtrack=1&key=8ad0ea50d7c77351c22c58485afc928202fc9a0d824262962e89c0ba0fc2f4cdff71b53ac553de24a2869828b80680e5e0b95dca96d1ba2b387a0545f28d307fe680c5c34f85014974055224ce14d7e25609c1645f8dd9bd5e64212162dd37beebe8799d090c732cab8b4fd1d3f0726925ca732f54cfecfd8d3ddfa3c2cc66e8&ascene=1&uin=MTc5OTk4OTk0Mg%3D%3D&devicetype=Windows+XP&version=62060841&lang=en&exportkey=A1AdOz2GvCbMLDFOCZdQPoE%3D&pass_ticket=DuHVyX3jEPFpCie02M%2F7Xh7WrZEVx52yyON5KbuXUolAirkp4eRhEfeQW1vDicrX&wx_header=0)
## 1. 可以先用几分钟时间稍微介绍下语义slam的大框架吗，和传统slam有什么区别和优势呢?不考虑算力等约束，理想的语义slam是怎样的，具有哪些特有功能？
```
总结：

1) CNN-SLAM，主要是用CNN网络进行特征匹配，SIVO是基于SVO，cubeslam物体级别的SLAM、SemanticFusion以及针对导航任务的MIT开源的SLAM算法Kimera。

2) DynaSLAM->针对动态场景的SLAM算法（用MaskRCNN来做动态物体删除），EmptyCities->针对动态场景动态SLAM算法（对被遮挡的场景恢复后再做SLAM），Stereo-SLAM（通过深度学习描述子+SLAM运用），类似于GCNV2 ，论文题目：Monocular Visual Odometry using Learned Repeatability and Description。清华大学开源的DXSLAM也是这种用learning提特征点的，以及物体级别的语义SLAM：CubeSLAM。
```

## 2. 语义的定义与意义在什么地方？我们是否需要语义？如何由任务来推导出我们需要的语义？
```
总结：

1) 语义SLAM的定义：语义 SLAM，跟传统 SLAM 的区别，是不是在于：语义 SLAM 是将更高层的语义信息作为特征来进行优化；传统 SLAM 是用关键点、描述子等低层图像特征来进行优化。我的理解：语义用来作为超像素（SuperPixel）：代替传统算法中的特征描述子；语义用来给导航等应用级任务提供线索，深度学习替代传统 SLAM 中的关键点、描述子等低层图像特征，应该算是语义 SLAM 所应用到的一个子模块，深度学习只能算是必要条件，不是充分条件。比如，有很多超像素，其实也没有用深度学习的方法，也可以提取。利用语义信息来代替传统的底层图像特征，有一个好处是：『语义级别的特征，做匹配，准确度和容易程度会更高』。比如之前，用底层图像特征，可能几百、上千个特征点，只要满足一定百分比的正确匹配即可；但是语义级别的匹配，可能就不需要那么多，因为语义信息更明确，我们对它的信任程度会更高。同意。因为人类看地图，肯定不是看一堆点云的点，或者 pose 的四元数。人类看的地图，就是这里有【地铁站】，那里有【参观】，前方有【红绿灯】。

2) 识别物体算语义，识别环境中的文字(TextSLAM)是否算语义？识别环境中的车道线等特征（AVP-SLAM）是否算语义？显著性应用是否算语义（SalientDSO）?更进一步，CarFusion/OrcVIO中用到的结构化特征点是否算语义？LIFT/SuperPoint是否算语义？单双目深度估计（CNN-SVO）是否算语义？用去模糊网络(MBO)是否算语义？用DL方式做优化（BA-Net）、用DL解决匹配问题（SuperGlue）是否算语义？以及终极问题：端到端的VO/SLAM（DeepVO）是否算语义？

3) 个人理解是像superpoint superglue这种很勉强算语义slam，或者用学习来做ba（视觉定位那个eth毕业的大佬就干过这事，甚至用学习来求解e矩阵）但是像cubeslam 或者将车道线，文本信息这些加进来应该可以算了，毕竟已经从点特征上升到了物体级别。

4) 这个问题我的理解是，还是从状态估计的基本定义出来，状态估计定了机器人的运动方程和观测方程，语义slam可以定义为观测方程中使用了除传统feature(orb,harris,sift等)的观测信息的SLAM方法，所以要定义这种观测应该具备哪些特性才能定义为语义观测，superpoint应该还是低层feature，但是自动驾驶里把路灯杆作为一种观测应该算是语义观测。我们一般说的语义就是像人的视觉系统一样，我们看某个地方第一反应是这是什么物体，而不是他的某个点的梯度是什么(harris feature)

5) 我觉得目前SLAM确实关注的更多是定位，但是SLAM本身应该也需要为导航服务，地图形式应该很重要，现在的语义地图感觉都是人工标注的，能不能构建一些可以自动构建可以导航服务的地图。我觉得语义的用处应该在这里。他们做的强化学习，用来导航，我觉得这就是直接摒弃了SLAM，另开了一套框架，直接就关注目标。我之前一直都觉得强化学习做这个，就是不靠谱，但是人家至少是在关注建图，AR/VR就不说了，在机器人里面我感觉SLAM本身就是为了定位和导航的，建图的目的也是为了定位和导航。之前这个问题我问过黄国权老师，黄老师的观点是目前关注定位是因为我们感知不够，无法像人一样灵活，所以目前还是几何为主，几何其实是为了弥补感知的不足。但是过于几何，是不是忽视了导航的需求。
```

## 3. 大尺度场景的地图真的需要实现全局的语义理解吗？局部（注意力区域）语义是否可以更好的平衡算力和精度需求？如何去做？
```
总结：

1) 我觉得可以结合起来：大尺度场景语义地图的建立，方便用于一些固定的、不太经常移动的标志或者物体；局部语义，可以用于一些当前的动态场景，比如移动的行人、车辆等。

2) 不需要的，可以考虑那种不同精度的地图，其实就像人一样，我们也没有完全记住所有信息，只是一个大概轮廓，局部够精准就行，大尺度去建立精准地图太耗费资源了。

3) 这个应该是根据具体产品对地图需求的定义来的，比如自动驾驶里，一个理想的地图应该要服务planning的任务，为了实现比较好的路径规划，就需要把地图中一些动态物体给扣掉，比如可行驶道路中临时停放的车辆，在采集数据的时候它是静止的，如果不抠掉，planning会认为这是不可行驶区域，就会影响航点规划。还是从planning的角度讨论这个问题，planning的一个重要工作是做prediction，通过预测周围交通参与者的行为来制定自己的未来轨迹，这个时候就需要对周围的物体有比较好的感知和运动估计了
```

## 4. 语义信息的引入如何能提升SLAM的定位精度，具体有哪些方式？
```
总结：

1) 主要是提高特征关联精度吧，感觉剔除动态物体，深度特征点，语义辅助特征点匹配都属于这种。再有我觉得可能还会提供一些高维度约束吧，比如面，立方框，二次曲面啥的。

2) dataassociation,数据关联，VSO Probabilistic Data Association for Semantic SLAM 这类通过构造包含语义信息的约束算是一种吧；X-View: Graph-Based Semantic Multi-View Localization这类关注长期回环检测的也应该说是一种；另外还有针对单目的Recovering stable scale in monocular SLAM using object-supplemented bundle adjustment这类尺度不确定性恢复的是不是也算。

3) 语义信息本身位置精度并不高（目前精度最高的就是像素级分割，但是也很难做到分割后的每个像素点进行关联；如果用关键点检测的方法来做，位置精度就更低了）。我觉得语义信息的特长在于，匹配时由于语义信息相比于底层图像信息比较明确，所以在匹配时，可以用更少的语义信息去做帧间匹配，从而提高匹配速度。但是精度上，我觉得可能还是类似关键点这种底层信息，精度更高一些。我们一般从光照，视角，尺度等角度定义一个feature是不是好的feature，从这个角度来说，语义feature都是很有优势的。比如构建一个scene graph来推理场景中物体的相对关系，虽然精度不高，但是更接近于人类感知环境的方式。
```

## 5. 语义label是否需要全局唯一，建图时如何剔除语义对象误匹配的情况
```
总结：

1) 这个应该是语义之后的一个步骤：关联（Association）关联有很多方式，有基于传统的几何特征的关联、也有基于深度学习的特征关联等。Label 是否需要全局唯一，我觉得是看语义信息是希望做局部导航用，还是想做全局建图，目的不同，答案也不同。如何剔除语义对象误匹配的情况：RANSAC；利用先验信息，如几何、速度等信息，进行不合理匹配的剔除；

2) 我觉得在这之前还有一步是参数化，如何用一个比较好的方式描述语义feature，比如传统feature使用的描述子向量；这里还有一个可以讨论的问题，是否可以定义一个统一结构处理不同的语义feature参数化。

3) 将特征利用网络抽象成一个特征向量，是一个方法。向量之前关联，可以用我们已知的各种度量距离（比如欧式距离、马氏距离等）。
```

## 6. 针对实例级别的语义信息，主流的数据关联方法有哪些呢？
```
总结：

1)  现在挺多的处理好像还是学习检测物体，然后用点信息来描述。或者像文本那样直接用文本信息关联。也可以参考其他领域，用物理结构那种。地平面支撑桌子或者椅子做约束这种。可以参考textslam，或者直接粗糙一点，比如地下车场的c01这种，记录下来，然后利用编号做匹配。比较相似的就是apriltag， 然后把apriltag换成文本。

2）把text紧耦合进视觉SLAM的pipeline.关键的idea是把每个检测到的text作为平面特征, 它包含足够的纹理和语义信息。文字特征是用三个参数表示的, 并且使用光度不变误差.

3）不知道大家有没有研究过visual tracking相关的工作，这对于语义的association有没有什么帮助？我还想提一个，1980年代，Yaakov Bar-Shalom所做的probabilistic data association会不会对语义的association有所帮助？Yaakov Bar-Shalom做的 probabilistic data association 还有 joint probabilistic data association 都是挺有意思的工作
```

## 7. 语义能否用于多传感器融合当中，有什么现成的应用框架？
```
总结：

     我觉得语义slam可能是解决不同传感器数据关联的一个很好的方式，比如雷达的feature和视觉的feature如何匹配，如果都能检测出一个high level的语义feature，并用相同的参数化表达，可能是一个比较好的方式.
```

## 8. 语义信息在地图导航中有没有应用？语义目标的纳入能够从哪些方面提升导航的精度？
```
总结：

1) 道路上的ar导航主要用到了车道线检测，和数据库里面的车道信息匹配，得到在哪个车道线上

2) 一个基础思路，语义目标建立后，将动态物体剔除，可以让slam使用干净的静态环境，避免动态野值干扰。另一个思路，语义目标建立后，如果有关于这个目标（无论是动态还是静态）的位姿信息，都可以纳入原本的slam框架作为测量来提升定位精度。

3) 语义信息在轻量级道路导航和辅助驾驶用的一般是矢量地图，拿到的地图里包含车道线杆牌等要素，视觉定位时检测车道线数量，杆，牌等特征，和地图里的矢量要素进行匹配，同时融合imu或轮速等运动信息，输出定位信息。
```