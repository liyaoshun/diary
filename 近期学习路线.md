# **边缘 AI**


## **模型轻量化**
```
项目内容描述：mobilenet、shufflenet、squeezenet等，模型量化、剪枝和蒸馏技术，网络的计算量和内存分析的工具，主干网络的轻量化，检测网络的轻量化，分割网络的轻量化，不同框架提供的加速方案。

项目使用的数据集：COCO，ADE20k，ImageNet

项目使用的算法：模型量化，模型剪枝和模型蒸馏

项目使用的工具：python，c/c++，pytorch，tensorflow，distiller，ncnn

项目预期结果：掌握轻量化网络设计准则，模型轻量化技术，能够上手操作一  个网络部署前的优化。
```
###  **轻量化网络结构设计**
```
本节课将讲解网络参数量、浮点运算数等模型评价指标、工具，以及分类网络， 检测网络，分割网络的轻量化设计。

课程提纲：
● 轻量化网络设计背景介绍
● 网络的计算量和内存分析工具
● 主干网络的轻量化
● 检测网络的轻量化
● 分割网络的轻量化
● 典型网络的设计思路
```

### **知识蒸馏优化、低秩分解优化**
```
本节课将讲解神经网络知识蒸馏优化、神经网络计算低秩分解加速计算方法。

课程提纲：
● 知识蒸馏方法介绍
● 知识蒸馏原理和步骤介绍
● 知识蒸馏训练方法缩减网络的实际分类网络演示
● 低秩分解原理
● 低秩分解加速计算在神经网络推理中的应用
```
### **网络剪枝**
```
本节课将讲解网络稀疏性原理，网络剪枝原则及剪枝的常见方法。

课程提纲：
● 网络剪枝的原理
● 常用的剪枝策略
● 神经网络框架中的剪枝功能介绍
● 剪枝的实际使用
```

### **网络量化**
```
本节课将讲解网络的低比特化，以及在AI芯片中的计算，实现网络量化的离线和在线感知的量化方法。

课程提纲：
● 网络量化的技术发展
● 不同离线量化算法的实现原理
● 神经网络框架中在线感知量化算法的原理及实现
● 实际案例
```


## **神经网络编译器**
```
项目内容描述：tvm，ncnn，mnn，tnn 各自的特点，对于神经网络的优化方案，tvm的具体设备的优化方案，算子融合，路径优化，内存优化，ncnn的网络的表示数据结构，ncnn的一些优化计算的思路，量化方法，mnn中的数据结构，模型转换和量化方法，tnn和ncnn的区别，系统架构，量化方法。

项目使用的算法：离线量化，在线感知量化

项目使用的工具：python，c/c++，tvm，ncnn，tnn，mnn

项目预期结果：对于神经网络编译器有全面的了解，对于主流神经网络编译器能够实践使用，完成模型到芯片所需要格式的转换。
```


## **通用芯片加速技术**
```
项目内容描述：cpu，arm对应的指令集级别的加速，编译器中具体的优化策略，simd，avx，sse，openblas，neon和cpu中对于卷积的运算加速方案，cpu上的具体实例，arm上的具体实例，环境配置，神经网络的例子，加速方案的组合和实际效果。

项目使用的算法：simd，avs，sse，blas，winograd

项目使用的工具：nnpack，qnnpack，lowpgemm，tvm，ncnn

项目预期结果：学员深入掌握cpu，arm等芯片的神经网络加速技术，并且通过一个例子来看具体的加速效果 。
```
### **神经网络编译器简介**
```
本节课将讲解tvm、ncnn、tnn、mnn的简要对比，tvm relay和网络转换，网络的编译优化和推理加速。

课程提纲：
● tvm、ncnn、tnn、mnn的简要对比
● tvm relay和网络转换
● 网络的编译优化和推理加速
● tvm的实际案例
```
### **ncnn**
```
本节课将讲解ncnn的系统架构图，数据结构，支持的框架，网络的表示，网络优化，量化，以及各平台的优化策略。

课程提纲：
● ncnn的系统架构图
● ncnn的数据结构及支持框架
● ncnn的网络表示
● ncnn网络优化，量化，及各平台的优化策略
```
### **tnn**
```
本节课将讲解tnn的系统架构图，数据结构，支持的框架，网络的表示，网络优化，量化，以及各平台的优化策略。

课程提纲：
● tnn的系统架构图
● tnn的数据结构及支持框架
● tnn的网络表示
● tnn网络优化，量化，及各平台的优化策略
```
### **mnn**
```
本节课将讲解mnn的系统架构图，数据结构，支持的框架，网络的表示，网络优化，量化，以及各平台的优化策略。

课程提纲：
● mnn的系统架构图
● mnn的数据结构及支持框架
● mnn的网络表示
● mnn网络优化，量化，及各平台的优化策略
```

### **cpu中的指令集优化**
```
本节课将讲解cpu中的指令集优化，simd、avx、sse方法，及tvm中对于cpu上神经网络加速的位置。

课程提纲：
● cpu中的指令集优化：simd，avx，sse方法
● tvm中对于cpu上神经网络加速的位置
```

### **其他介绍**
```
arm中的神经网络加速

本节课将讲解arm中的neon优化，及ncnn，tnn和mnn的实现，并结合实际例子来看具体的加速效果。

课程提纲：
● arm中的neon优化
● ncnn，tnn和mnn实现的讲解
● 具体加速效果的实际案例


卷积计算的优化算法
本节课将讲解卷积计算的优化算法，包括winograd等。


神经网络加速库

本节课将讲解openblas库的优化，nnpack/qnnpack的优化，及lowpgemm。

课程提纲：
● openblas库的优化
● nnpack/qnnpack的优化
● lowpgemm


gpu上神经网络的运行和加速
本节课将讲解gpu与cpu计算加速的区别，英伟达gpu的原生cuda加速方法，及推理侧tensorrt的使用。

课程提纲：
● gpu与cpu计算加速的区别
● 英伟达gpu的原生cuda加速方法
● 推理侧tensorrt的使用


gpu加速通用加速库

本节课将讲解通用加速库cublas，vulkan，opencl的使用。

课程提纲：
● 通用加速库cublas的使用
● Vulkan的使用
● opencl的使用
```




## **专用芯片加速技术**
```
项目内容描述：gpu和k210 npu及各自神经网络编译器中的加速优化技术，gpu上的cuda加速的方法，cublas，opencl，vulkan的开发例子，nncase上编译一个网络，k210开发板环境配置及人脸检测模型的部署

项目使用的算法：人脸检测

项目使用的工具（编程语言、工具、技术等）：Python，C/C++，opencl，vulkan，nncase

项目预期结果：学员可以掌握gpu及npu上神经网络的编译加速，并且通过一个具体的例子来完成人脸检测模型在k210芯片上的部署 。
```

### **dsp，fpga，npu专用加速计算**
```
本节课将讲解dsp，fpga，npu的专用加速计算。

课程提纲：
● dsp计算加速
● fpga计算加速
● npu专用加速计算
```

### **npu使用**
```
本节课将以嘉楠科技的k210为例，实现一个人脸检测案例。

课程提纲：
● 嘉楠科技k210芯片介绍
● nncase人脸检测案例
```